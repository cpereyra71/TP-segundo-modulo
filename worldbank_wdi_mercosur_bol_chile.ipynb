{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# World Bank WDI – Economy & Growth + External Debt (Mercosur + Bolivia + Chile)\n",
        "\n",
        "Este notebook descarga **todos los indicadores** de los tópicos *Economy & Growth* y *External debt / Debt & financial flows*,\n",
        "y baja las series para **Argentina, Brasil, Paraguay, Uruguay, Bolivia y Chile** usando la API del Banco Mundial.\n",
        "\n",
        "**Salida**: CSV/Excel con metadatos de indicadores y observaciones (país–indicador–año).\n",
        "\n",
        "> Requisitos: `pandas`, `requests`, (opcional) `xlsxwriter`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pandas requests xlsxwriter\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "BASE = \"https://api.worldbank.org/v2\"\n",
        "\n",
        "# Países: Mercosur + Bolivia + Chile\n",
        "COUNTRIES = {\n",
        "    \"Argentina\": \"ARG\",\n",
        "    \"Brasil\": \"BRA\",\n",
        "    \"Paraguay\": \"PRY\",\n",
        "    \"Uruguay\": \"URY\",\n",
        "    \"Bolivia\": \"BOL\",\n",
        "    \"Chile\": \"CHL\",\n",
        "}\n",
        "\n",
        "# Palabras clave para encontrar los tópicos deseados\n",
        "TOPIC_NAME_KEYWORDS = {\n",
        "    \"economy_growth\": [\"economy\", \"growth\"],\n",
        "    \"external_debt\": [\"debt\"],  # incluye \"External debt\", \"Debt & financial flows\"\n",
        "}\n",
        "\n",
        "# Rango de años (cambiar a gusto)\n",
        "START_YEAR = 2000\n",
        "END_YEAR = 2024\n",
        "\n",
        "# Prefijo de archivos de salida\n",
        "OUT_PREFIX = \"worldbank_wdi_mercosur_bol_chile\"\n",
        "\n",
        "# Pausa entre requests (cortesía a la API)\n",
        "REQUEST_SLEEP = 0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funciones auxiliares\n",
        "- `_get_json`: GET con reintentos\n",
        "- `list_topics`: lista de tópicos\n",
        "- `pick_topic_ids_by_keywords`: busca IDs de tópicos por palabras clave\n",
        "- `list_indicators_for_topic(s)`: lista indicadores de un tópico (con paginación)\n",
        "- `fetch_series`: descarga serie por indicador/países/años (con paginación)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _get_json(url, params=None, max_retries=5, backoff=1.5):\n",
        "    for attempt in range(1, max_retries+1):\n",
        "        try:\n",
        "            r = requests.get(url, params=params, timeout=60)\n",
        "            r.raise_for_status()\n",
        "            return r.json()\n",
        "        except Exception:\n",
        "            if attempt == max_retries:\n",
        "                raise\n",
        "            time.sleep(backoff ** attempt)\n",
        "\n",
        "def list_topics():\n",
        "    j = _get_json(f\"{BASE}/topic\", params={\"format\": \"json\"})\n",
        "    return pd.DataFrame(j[1])[ [\"id\",\"value\"] ]\n",
        "\n",
        "def pick_topic_ids_by_keywords(topics_df, keywords):\n",
        "    ids = []\n",
        "    for _, row in topics_df.iterrows():\n",
        "        name = str(row[\"value\"]).lower()\n",
        "        if all(kw.lower() in name for kw in keywords):\n",
        "            ids.append(str(row[\"id\"]))\n",
        "    return ids\n",
        "\n",
        "def list_indicators_for_topic(topic_id):\n",
        "    indicators = []\n",
        "    page = 1\n",
        "    while True:\n",
        "        j = _get_json(f\"{BASE}/topic/{topic_id}/indicator\", params={\n",
        "            \"format\": \"json\",\n",
        "            \"per_page\": 20000,\n",
        "            \"page\": page\n",
        "        })\n",
        "        meta = j[0]\n",
        "        data = j[1] if len(j) > 1 else []\n",
        "        indicators.extend(data)\n",
        "        if page >= meta.get(\"pages\", 1):\n",
        "            break\n",
        "        page += 1\n",
        "        time.sleep(0.2)\n",
        "    if not indicators:\n",
        "        return pd.DataFrame(columns=[\"id\",\"name\",\"unit\",\"sourceNote\",\"sourceOrganization\",\"topic_id\"])\n",
        "    df = pd.DataFrame(indicators)\n",
        "    df[\"topic_id\"] = topic_id\n",
        "    return df.reindex(columns=[\"id\",\"name\",\"unit\",\"sourceNote\",\"sourceOrganization\",\"topic_id\"])\n",
        "\n",
        "def list_indicators_for_topics(topic_ids):\n",
        "    frames = []\n",
        "    for tid in topic_ids:\n",
        "        frames.append(list_indicators_for_topic(tid))\n",
        "    if frames:\n",
        "        df = pd.concat(frames, ignore_index=True).drop_duplicates(subset=[\"id\"]).reset_index(drop=True)\n",
        "    else:\n",
        "        df = pd.DataFrame(columns=[\"id\",\"name\",\"unit\",\"sourceNote\",\"sourceOrganization\",\"topic_id\"])\n",
        "    return df\n",
        "\n",
        "def fetch_series(indicator_code, country_codes, start_year, end_year):\n",
        "    series = []\n",
        "    page = 1\n",
        "    codes = \";\".join(country_codes)\n",
        "    while True:\n",
        "        j = _get_json(f\"{BASE}/country/{codes}/indicator/{indicator_code}\", params={\n",
        "            \"date\": f\"{start_year}:{end_year}\",\n",
        "            \"format\": \"json\",\n",
        "            \"per_page\": 20000,\n",
        "            \"page\": page\n",
        "        })\n",
        "        meta = j[0]\n",
        "        data = j[1] if len(j) > 1 else []\n",
        "        for item in data:\n",
        "            series.append({\n",
        "                \"country_iso3\": item.get(\"countryiso3code\"),\n",
        "                \"country\": (item.get(\"country\") or {}).get(\"value\"),\n",
        "                \"indicator\": indicator_code,\n",
        "                \"date\": item.get(\"date\"),\n",
        "                \"value\": item.get(\"value\")\n",
        "            })\n",
        "        if page >= meta.get(\"pages\", 1):\n",
        "            break\n",
        "        page += 1\n",
        "        time.sleep(0.25)\n",
        "    if not series:\n",
        "        return pd.DataFrame(columns=[\"country_iso3\",\"country\",\"indicator\",\"year\",\"value\"])\n",
        "    df = pd.DataFrame(series)\n",
        "    df[\"year\"] = pd.to_numeric(df[\"date\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    df = df.drop(columns=[\"date\"])\n",
        "    return df[[\"country_iso3\",\"country\",\"indicator\",\"year\",\"value\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Buscar IDs de tópicos y listar indicadores\n",
        "Esto detecta los IDs de *Economy & Growth* y *External debt* y guarda los metadatos en `*_indicators_meta.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics_df = list_topics()\n",
        "display(topics_df)\n",
        "\n",
        "econ_ids = pick_topic_ids_by_keywords(topics_df, TOPIC_NAME_KEYWORDS[\"economy_growth\"])\n",
        "debt_ids = pick_topic_ids_by_keywords(topics_df, TOPIC_NAME_KEYWORDS[\"external_debt\"])\n",
        "topic_ids = list(dict.fromkeys(econ_ids + debt_ids))  # dedupe\n",
        "\n",
        "print(\"Economy/Growth topic IDs:\", econ_ids)\n",
        "print(\"External debt topic IDs:\", debt_ids)\n",
        "print(\"Using topic IDs:\", topic_ids)\n",
        "\n",
        "indicators_df = list_indicators_for_topics(topic_ids)\n",
        "indicators_df = indicators_df.rename(columns={\n",
        "    \"id\":\"indicator_code\",\n",
        "    \"name\":\"indicator_name\",\n",
        "    \"unit\":\"unit\",\n",
        "    \"sourceNote\":\"source_note\",\n",
        "    \"sourceOrganization\":\"source_org\"\n",
        "})\n",
        "indicators_df[\"topic_ids\"] = indicators_df[\"topic_id\"]\n",
        "indicators_df = indicators_df.drop(columns=[\"topic_id\"]).sort_values(\"indicator_code\").reset_index(drop=True)\n",
        "display(indicators_df.head())\n",
        "\n",
        "indicators_path = f\"{OUT_PREFIX}_indicators_meta.csv\"\n",
        "indicators_df.to_csv(indicators_path, index=False, encoding=\"utf-8\")\n",
        "print(\"Guardado:\", indicators_path, \"(n=\", len(indicators_df), \")\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Descargar todas las series para los países seleccionados\n",
        "Crea un CSV `*_observations.csv` y un Excel con dos hojas (`indicators_meta` y `observations`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "country_codes = list(COUNTRIES.values())\n",
        "all_obs = []\n",
        "\n",
        "for i, row in indicators_df.iterrows():\n",
        "    ind = row[\"indicator_code\"]\n",
        "    try:\n",
        "        obs = fetch_series(ind, country_codes, START_YEAR, END_YEAR)\n",
        "        if not obs.empty:\n",
        "            all_obs.append(obs)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error en indicador {ind}: {e}\")\n",
        "    time.sleep(REQUEST_SLEEP)\n",
        "    if (i+1) % 25 == 0:\n",
        "        print(f\"Progreso: {i+1}/{len(indicators_df)} indicadores\")\n",
        "\n",
        "if all_obs:\n",
        "    observations_df = pd.concat(all_obs, ignore_index=True)\n",
        "else:\n",
        "    observations_df = pd.DataFrame(columns=[\"country_iso3\",\"country\",\"indicator\",\"year\",\"value\"])\n",
        "\n",
        "display(observations_df.head())\n",
        "\n",
        "obs_path = f\"{OUT_PREFIX}_observations.csv\"\n",
        "observations_df.to_csv(obs_path, index=False, encoding=\"utf-8\")\n",
        "print(\"Guardado:\", obs_path, \"(filas=\", len(observations_df), \")\")\n",
        "\n",
        "xlsx_path = f\"{OUT_PREFIX}.xlsx\"\n",
        "with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as xw:\n",
        "    indicators_df.to_excel(xw, sheet_name=\"indicators_meta\", index=False)\n",
        "    observations_df.to_excel(xw, sheet_name=\"observations\", index=False)\n",
        "print(\"Guardado:\", xlsx_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Resumen rápido (opcional)\n",
        "Cuenta puntos por país/indicador para chequear cobertura.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    summary = (observations_df\n",
        "               .groupby([\"country_iso3\",\"indicator\"], dropna=False)[\"value\"]\n",
        "               .count()\n",
        "               .reset_index(name=\"num_points\")\n",
        "               .sort_values([\"country_iso3\",\"num_points\"], ascending=[True, False]))\n",
        "    display(summary.head(20))\n",
        "    summary_path = f\"{OUT_PREFIX}_summary_counts.csv\"\n",
        "    summary.to_csv(summary_path, index=False, encoding=\"utf-8\")\n",
        "    print(\"Guardado:\", summary_path)\n",
        "except Exception as e:\n",
        "    print(\"No se pudo generar el resumen:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}